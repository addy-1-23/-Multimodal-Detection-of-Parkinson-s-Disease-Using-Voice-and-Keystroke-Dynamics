# -*- coding: utf-8 -*-
"""Parkinsons_Research_Pap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y2ReiQh2B2adKG0pl260EgK3Gaxbvt3u
"""

!pip install streamlit shap scikit-learn catboost matplotlib seaborn xgboost pyngrok --quiet


app_code = """
# Upgrade of Parkinson's Multimodal Detection Streamlit App with Advanced Models and Evaluation

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import shap

from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, f1_score, average_precision_score, precision_recall_curve
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import VotingClassifier, StackingClassifier
from sklearn.utils import resample

import xgboost as xgb
import lightgbm as lgb
import catboost as cb

st.set_page_config(layout="wide")
st.title("Multimodal Detection of Parkinsonâ€™s Disease Using Voice and Keystroke Dynamics")
st.markdown("### Research-Enhanced AI Tool for Parkinson's Detection")

@st.cache_data
def load_data():
    voice_data = pd.read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/parkinsons/parkinsons.data")
    voice_data.drop("name", axis=1, inplace=True)
    return voice_data

data = load_data()

# Add synthetic keystroke features
def add_typing_features(df):
    np.random.seed(42)
    df['avg_dwell_time'] = np.random.uniform(100, 300, len(df))
    df['avg_flight_time'] = np.random.uniform(100, 300, len(df))
    df['typing_speed'] = np.random.uniform(100, 300, len(df))
    df['key_press_variance'] = np.random.uniform(50, 150, len(df))
    return df

import re

data = add_typing_features(data)
X = data.drop('status', axis=1)
y = data['status']

# Sanitize column names 
X.columns = [re.sub(r'\W|^(?=\d)', '_', col) for col in X.columns]


# Define models
xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')
lgb_clf = lgb.LGBMClassifier()
cat_clf = cb.CatBoostClassifier(verbose=0)
svm_clf = SVC(probability=True)

# Ensemble model
stacked_model = StackingClassifier(
    estimators=[('xgb', xgb_clf), ('svm', svm_clf), ('cat', cat_clf)],
    final_estimator=LogisticRegression(),
    cv=5
)

models = {
    'XGBoost': xgb_clf,
    'LightGBM': lgb_clf,
    'CatBoost': cat_clf,
    'SVM': svm_clf,
    'Stacked Ensemble': stacked_model
}

# Nested cross-validation and bootstrapping
st.subheader("Model Evaluation with Nested CV and Bootstrapping")
results = {}
skf_outer = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for name, model in models.items():
    aucs, f1s, pr_aucs = [], [], []
    for train_idx, test_idx in skf_outer.split(X, y):
        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1]
        aucs.append(roc_auc_score(y_test, y_proba))
        f1s.append(f1_score(y_test, y_pred))
        pr_aucs.append(average_precision_score(y_test, y_proba))
    results[name] = {
        "AUC": np.mean(aucs),
        "F1": np.mean(f1s),
        "PR-AUC": np.mean(pr_aucs)
    }

comparison_df = pd.DataFrame(results).T.reset_index().rename(columns={"index": "Model"})
comparison_df[["AUC", "F1", "PR-AUC"]] = comparison_df[["AUC", "F1", "PR-AUC"]].round(3)
st.dataframe(comparison_df)

# Final model: Stacked Ensemble
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)
stacked_model.fit(X_train, y_train)
y_pred = stacked_model.predict(X_test)
y_proba = stacked_model.predict_proba(X_test)[:, 1]

st.subheader("Final Model (Stacked Ensemble)")
st.text(classification_report(y_test, y_pred))
st.write("F1 Score:", f1_score(y_test, y_pred))
st.write("AUC Score:", roc_auc_score(y_test, y_proba))

st.subheader("Confusion Matrix")
cm = confusion_matrix(y_test, y_pred)
fig_cm, ax_cm = plt.subplots()
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax_cm)
st.pyplot(fig_cm)

st.subheader("Precision-Recall Curve")
precision, recall, _ = precision_recall_curve(y_test, y_proba)
fig_pr, ax_pr = plt.subplots()
ax_pr.plot(recall, precision, label="PR-AUC = {:.2f}".format(average_precision_score(y_test, y_proba)))
ax_pr.set_xlabel("Recall")
ax_pr.set_ylabel("Precision")
ax_pr.legend()
st.pyplot(fig_pr)

st.subheader("SHAP Interaction Values (CatBoost)")
explainer = shap.TreeExplainer(cat_clf)
shap_values = explainer.shap_values(X_test)
fig_shap = plt.figure(figsize=(10, 6))
shap.summary_plot(shap_values, X_test, plot_type="dot", show=False)
st.pyplot(fig_shap)
plt.close(fig_shap)

st.sidebar.header("Patient Data Input")
input_data = {col: st.sidebar.slider(col, float(X[col].min()), float(X[col].max()), float(X[col].mean())) for col in X.columns}
input_df = pd.DataFrame([input_data])
prediction = stacked_model.predict(input_df)[0]
prob = stacked_model.predict_proba(input_df)[0][1]

st.subheader("Prediction for New Patient")
prediction_label = "Parkinson's" if prediction == 1 else "Healthy"
st.write(f"Prediction: {prediction_label}")
st.write(f"Probability of Parkinson's: {prob:.2f}")


"""

with open("parkinsons_multimodal_research_app.py", "w") as f:
    f.write(app_code)


!nohup streamlit run parkinsons_multimodal_research_app.py --server.port 8501 --server.headless true --server.enableCORS false > streamlit.log 2>&1 &


from pyngrok import ngrok

# Set your ngrok auth token here (replace below with your actual token)
ngrok.set_auth_token("Enter your ngrok token")

# Open tunnel to streamlit port 8501
public_url = ngrok.connect(8501)
print(f"Streamlit app should be live at: {public_url}")



